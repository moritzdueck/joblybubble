{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3e6cd6",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abadef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cd5f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from json2html import json2html\n",
    "\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe1d70",
   "metadata": {},
   "source": [
    "# Job Listing URL Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87d1837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SCRAPEOPS_API_KEY = '4ef5c0f1-4b24-4b53-a5c4-f7c4ac284460'\n",
    "\n",
    "def get_headers_list():\n",
    "  response = requests.get('http://headers.scrapeops.io/v1/browser-headers?api_key=' + SCRAPEOPS_API_KEY)\n",
    "  json_response = response.json()\n",
    "  return json_response.get('result', [])\n",
    "\n",
    "def get_random_header(header_list):\n",
    "  random_index = randint(0, len(header_list) - 1)\n",
    "  return header_list[random_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d4880da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_agents_list = [\n",
    "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "]\n",
    "\n",
    "#headers={\"User-Agent\": \"Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148\"}\n",
    "\n",
    "\n",
    "def get_indeed_search_url(keyword, location, offset=0):\n",
    "    parameters = {\"q\": keyword, \"l\": location, \"filter\": 0, \"start\": offset}\n",
    "    return \"https://www.indeed.com/jobs?\" + urlencode(parameters)\n",
    "\n",
    "def get_indeed_job_urls(keyword_list, location_list):\n",
    "\n",
    "    job_id_list = []\n",
    "    job_url_list = []\n",
    "    header_list = get_headers_list()\n",
    "\n",
    "    ## Loop Through Indeed Pages Until No More Jobs\n",
    "    for keyword in keyword_list:\n",
    "        for location in location_list:\n",
    "            for offset in range(0, 1010, 10):\n",
    "                try:\n",
    "                    indeed_jobs_url = get_indeed_search_url(keyword, location, offset)\n",
    "                    \n",
    "                    response = requests.get(indeed_jobs_url, headers=get_random_header(header_list))\n",
    "                    print(response)\n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        script_tag  = re.findall(r'window.mosaic.providerData\\[\"mosaic-provider-jobcards\"\\]=(\\{.+?\\});', response.text)\n",
    "                        if script_tag is not None:\n",
    "                            json_blob = json.loads(script_tag[0])\n",
    "                            jobs_list = json_blob['metaData']['mosaicProviderJobCardsModel']['results']\n",
    "                            for index, job in enumerate(jobs_list):\n",
    "                                if job.get('jobkey') is not None:\n",
    "                                    job_id_list.append(job.get('jobkey'))\n",
    "\n",
    "                            ## If response contains less than 10 jobs then stop pagination\n",
    "                            if len(jobs_list) < 10:\n",
    "                                break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print('Error', e)\n",
    "    \n",
    "    print(job_id_list)\n",
    "                    \n",
    "     \n",
    "    for idx in job_id_list:\n",
    "        indeed_job_url = 'https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=' + idx\n",
    "        job_url_list.append(indeed_job_url)\n",
    "\n",
    "    return job_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e0b29af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n",
      "<Response [403]>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m keyword_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftware engineer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m location_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalifornia\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_indeed_job_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyword_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 27\u001b[0m, in \u001b[0;36mget_indeed_job_urls\u001b[1;34m(keyword_list, location_list)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     indeed_jobs_url \u001b[38;5;241m=\u001b[39m get_indeed_search_url(keyword, location, offset)\n\u001b[1;32m---> 27\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindeed_jobs_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_random_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\requests\\adapters.py:487\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    484\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 487\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[0;32m   1045\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1046\u001b[0m         (\n\u001b[0;32m   1047\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1052\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1053\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m    365\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[0;32m    183\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stable_diff\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m     84\u001b[0m         sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m     \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sock\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    ## Job Search Parameters\n",
    "    keyword_list = ['software engineer']\n",
    "    location_list = ['California']\n",
    "    ids = get_indeed_job_urls(keyword_list, location_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc50587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbec77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb486373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a501a6f",
   "metadata": {},
   "source": [
    "# Static parameters\n",
    "These parameters are used to filter criteria for the [ClimateBase.org Jobs](https://climatebase.org/jobs?l=&q=&p=0&remote=false) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548f2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://climatebase.org/jobs?l=&q=&p=0&remote=false\n",
    "domain_name = \"https://climatebase.org\"\n",
    "url_path = \"/jobs?l=&q=&p=0&remote=false\"\n",
    "\n",
    "# Job types\n",
    "#https://climatebase.org/jobs?l=&q=&job_types=Full+time+role&p=0&remote=false\n",
    "d_job_types  = {0:\"\", 1:\"Full+time+role\", 2:\"Internship\"}\n",
    "\n",
    "# Role type\n",
    "#https://climatebase.org/jobs?l=&q=&categories=Data+Analyst&p=0&remote=false\n",
    "d_categories = {0:\"\", 1:\"Data+Analyst\", 2:\"Data+Scientist\", 3:\"Research\"}\n",
    "\n",
    "# Remote\n",
    "#https://climatebase.org/jobs?l=Remote&q=&p=0&remote=true\n",
    "d_remote = {0:\"\", 1:\"true\", 2:\"false\"}\n",
    "\n",
    "css_object_class = \"list_card\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff7afdc",
   "metadata": {},
   "source": [
    "# User-defined parameters\n",
    "These parameters are the filtering criteria for the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7dd2d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job type: Fulltimerole\n",
      "Category: DataScientist\n",
      "Remote: true\n"
     ]
    }
   ],
   "source": [
    "job_types = d_job_types[1]\n",
    "print(\"Job type: \" + job_types.replace(\"+\", \"\"))\n",
    "\n",
    "categories = d_categories[2]\n",
    "print(\"Category: \" + categories.replace(\"+\", \"\"))\n",
    "\n",
    "remote = d_remote[1]\n",
    "print(\"Remote: \" + remote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb383015",
   "metadata": {},
   "source": [
    "# User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ded7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_filter(input_text, to_insert):\n",
    "    \"\"\"\n",
    "    This function formats the url structure to make a filtered query.\n",
    "    \"\"\"\n",
    "    # Find the index where \"&p=\" starts\n",
    "    index = input_text.find(\"&p=\")\n",
    "\n",
    "    # Insert the text to the left of \"&p=\"\n",
    "    new_string = input_text[:index] + to_insert + input_text[index:]\n",
    "    \n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59b0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_remote(input_text):\n",
    "    \"\"\"\n",
    "    This function is similar to insert_filter(), but is specific for the \"remote\" filtering.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_string = input_text.replace(\"?l=\", \"?l=Remote\")\n",
    "    new_string = input_text.replace(\"&remote=false\", \"&remote=true\")\n",
    "\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d723b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_css_object(url_path, css_object_class):\n",
    "    \"\"\"\n",
    "    Given a CSS object class, this scraper will obtain the relevant information from the website.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = domain_name + url_path\n",
    "    #\"https://climatebase.org/jobs?l=&q=&categories=Data+Scientist&p=0&remote=true\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all elements with class=\"list_card\"\n",
    "    found_objects = soup.find_all(class_=css_object_class)\n",
    "\n",
    "    return found_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decb6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_title(current_path):\n",
    "    \"\"\"\n",
    "    This function will obtain the job title from a predefined CSS object specific to \n",
    "    the ClimateBase.org website.\n",
    "    \"\"\"\n",
    "    \n",
    "    html_title = scraping_css_object(current_path, \"fcPVcr\")\n",
    "    soup = BeautifulSoup(str(html_title), 'html.parser')\n",
    "    title = soup.find('h1', {'class': 'PageLayout__Title-sc-1ri9r3s-4 fcPVcr'}).text\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b05128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_job_description(current_path):\n",
    "    \"\"\"\n",
    "    This function will obtain the job description from a predefined CSS object specific to\n",
    "    the ClimateBase.org website.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mining job description\n",
    "    html_bodytext = scraping_css_object(current_path, \"EPUZp\")\n",
    "    soup = BeautifulSoup(str(html_bodytext), 'html.parser')\n",
    "    bodytext = soup.div.text.strip()\n",
    "\n",
    "    return bodytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025141a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt_prompt(title, bodytext):\n",
    "    \"\"\"\n",
    "    This function contains the prompt with the set of rules that are to be sent to ChatGPT to process a text.\n",
    "    \"\"\"    \n",
    "    \n",
    "    categories = \"\"\"\n",
    "    * Job title\n",
    "    * Company name\n",
    "    * Company mission\n",
    "    * Company values \n",
    "    * Company products or services\n",
    "    * Job responsibilities\n",
    "    * Desired software skills\n",
    "    * Education\n",
    "    * Required Job Experience\n",
    "    * Equal Employment Opportunity\n",
    "    * Salary\n",
    "    * Benefits\n",
    "    * Location\n",
    "    * Type of employment\n",
    "    * URL\n",
    "    \"\"\"\n",
    "    json_keys = [category.strip('* ').lower().replace(' ', '_') for category in categories.strip().splitlines()]\n",
    "\n",
    "    text_prompt = f\"\"\"I will prompt you with a job description contained within ```, and I want your help to extract and categorize its information. Before we begin, please follow these rules: \n",
    "\n",
    "    1. Replace any double quotes in the text with single quotes.\n",
    "    2. Extract and categorize the information from the job description for the following categories:{categories}\n",
    "    3. Please provide your answers in a JSON object format. The keys will be the same as the categories but in lower case and with spaces replaced by underscores. These are respectively and in order: {json_keys}.\n",
    "    4. Use a consistent structure for all data entries. Never create nested values. Separate them with a delimiter such as \";\" instead.\n",
    "    5. If any category has no available information, please include a \"null\" value for the corresponding key in the JSON object. \n",
    "    6. Make the categorizations as concise as possible, maybe even as keywords. Be as economic as possible.\n",
    "    7. Avoid paragraphs of text or long sentences. \n",
    "    8. Avoid redundant text.\n",
    "\n",
    "    Please keep these rules in mind when categorizing the job description. Let's begin!: \n",
    "    \"\"\" + \"```Job title: \" + title + \".\\n\\n \"+ bodytext + \" URL: \" + domain_name + current_path + \" \\n```\"\n",
    "    \n",
    "    return text_prompt\n",
    "\n",
    "#display(Markdown(chatgpt_prompt(title, bodytext)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf021b0",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77a1c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting variables for filtering criteria on the website.\n",
    "\n",
    "if job_types != \"\":\n",
    "    url_path = insert_filter(url_path, \"&job_types=\" + job_types)\n",
    "    \n",
    "if categories != \"\":\n",
    "    url_path = insert_filter(url_path, \"&categories=\" + categories)\n",
    "\n",
    "if remote != \"\":    \n",
    "    url_path = define_remote(url_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc86a4cb",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19b940a",
   "metadata": {},
   "source": [
    "## > Scraping url's\n",
    "Mining url's from main site by filtered criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2289b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of websites with job different job descriptions is obtained after filtering.\n",
    "scraped_url_paths = [element['href'] for element in scraping_css_object(url_path, css_object_class)]\n",
    "\n",
    "# Example: Visualization of the complete url\n",
    "#domain_name + scraped_url_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ea26e",
   "metadata": {},
   "source": [
    "## > Scraping information from each url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f9f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [21:12<00:00, 12.72s/it]\n"
     ]
    }
   ],
   "source": [
    "json_list = []\n",
    "\n",
    "for current_path in tqdm(scraped_url_paths):\n",
    "    try:\n",
    "        # Scraping job title\n",
    "        title = scrape_title(current_path)\n",
    "\n",
    "        # Scraping job description\n",
    "        bodytext = scrape_job_description(current_path)\n",
    "\n",
    "        # Redacting prompt for ChatGPT\n",
    "        text_prompt = chatgpt_prompt(title, bodytext)\n",
    "\n",
    "        # Calling ChatGPT\n",
    "        reply = call_openai_api(text_prompt, tokens = 1000)\n",
    "        reply = reply.replace(\"\\n\", \"\") \n",
    "\n",
    "        json_object = json.loads(reply)\n",
    "\n",
    "        # Collecting JSON objects\n",
    "        json_list.append(json_object)\n",
    "        \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3564493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230609_Data+Scientist_Full+time+role_remote_true\n"
     ]
    }
   ],
   "source": [
    "current_date = datetime.now()\n",
    "formatted_date = current_date.strftime(\"%y%m%d\")\n",
    "\n",
    "filename = formatted_date + '_' + categories + \"_\" + job_types + \"_\" + \"remote_\" + remote\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc2190b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting JSON file\n",
    "with open(filename + '.json', 'w') as f:\n",
    "    json.dump(json_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130c969",
   "metadata": {},
   "source": [
    "# Transforming JSON file into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fdbddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"230609_Data+Scientist_Full+time+role_remote_true.json\"\n",
    "json_file = json.load(open(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e7ba240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 15)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=json_file[0].keys())\n",
    "\n",
    "for i in range(len(json_file)):\n",
    "    y = pd.json_normalize(json_file[i])\n",
    "    \n",
    "    # Patch:\n",
    "    y.columns= y.columns.str.lower()\n",
    "\n",
    "    df = pd.concat([df, y], ignore_index=True)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.to_csv(\"{}.csv\".format(filename), index=False,  sep='~')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546dee6",
   "metadata": {},
   "source": [
    "# Displaying individual JSON objects as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77fdf76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <style>\n",
       "      table {\n",
       "        width: 60%;\n",
       "        border-collapse: collapse;\n",
       "      }\n",
       "      th, td {\n",
       "        padding: 8px;\n",
       "        border-bottom: 1px solid #ddd;\n",
       "        word-wrap: break-word;\n",
       "      }\n",
       "      th:nth-child(2), td:nth-child(2) {\n",
       "        width: 400px;\n",
       "      }\n",
       "    </style>\n",
       "    <table border=\"1\"><tr><th>job_title</th><td>2024 California Regional Office Clerkship</td></tr><tr><th>company_name</th><td>Earthjustice</td></tr><tr><th>company_mission</th><td>To protect the environment and promote environmental justice through lawsuits and administrative advocacy under federal and California environmental laws.</td></tr><tr><th>company_values</th><td>None</td></tr><tr><th>company_products_or_services</th><td>None</td></tr><tr><th>job_responsibilities</th><td>Working alongside attorneys and advocates in San Francisco and Los Angeles offices, participating in the Diversity and Inclusion Fellowship Program organized by the Environmental Law Section of the California Lawyers Association (CLA Section).</td></tr><tr><th>desired_software_skills</th><td>None</td></tr><tr><th>education</th><td>Law degree.</td></tr><tr><th>required_job_experience</th><td>None specified.</td></tr><tr><th>equal_employment_opportunity</th><td>Equal opportunity employer and considers applicants for all positions without regard to race, color, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, or any other legally protected status.</td></tr><tr><th>salary</th><td>None</td></tr><tr><th>benefits</th><td>None</td></tr><tr><th>location</th><td>San Francisco and Los Angeles, California.</td></tr><tr><th>type_of_employment</th><td>Summer law clerkship.</td></tr><tr><th>url</th><td>https://climatebase.org/job/46569513/2024-california-regional-office-clerkship?source=jobs_directory</td></tr></table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert JSON to HTML\n",
    "json_object = json_file[-1]\n",
    "html_table = json2html.convert(json.dumps(json_object))\n",
    "\n",
    "display_json_as_html = f\"\"\"\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <style>\n",
    "      table {{\n",
    "        width: 60%;\n",
    "        border-collapse: collapse;\n",
    "      }}\n",
    "      th, td {{\n",
    "        padding: 8px;\n",
    "        border-bottom: 1px solid #ddd;\n",
    "        word-wrap: break-word;\n",
    "      }}\n",
    "      th:nth-child(2), td:nth-child(2) {{\n",
    "        width: 400px;\n",
    "      }}\n",
    "    </style>\n",
    "    {html_table}\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(display_json_as_html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
